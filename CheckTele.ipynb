{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38c6a7f-cb8d-450a-981c-1def44dccbea",
      "metadata": {
        "id": "f38c6a7f-cb8d-450a-981c-1def44dccbea"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, date\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "import glob\n",
        "from typing import Optional, Union, Dict\n",
        "import xlsxwriter\n",
        "from xlsxwriter.utility import xl_rowcol_to_cell\n",
        "\n",
        "# ==============================================================================\n",
        "# 設定クラス\n",
        "# ==============================================================================\n",
        "\n",
        "class ReportConfig:\n",
        "    \"\"\"\n",
        "    レポート作成に関するすべての設定値を一元管理するクラス。\n",
        "\n",
        "    このクラスは、ファイルパス、シート名、読み込み設定、Excelのスタイル定義など、\n",
        "    スクリプト全体で使用される定数や設定値を属性として一元的に管理します。\n",
        "\n",
        "    Attributes:\n",
        "        FILES (dict): 入力ファイルのパス情報。\n",
        "        SHEET_NAMES (dict): 出力Excelのシート名定義。\n",
        "        LOAD_CONFIG (dict): 各種データ読み込み時の設定値。\n",
        "        COL_NAMES_CONSTRUCTION_PREP (list): 構築準備データの列名リスト。\n",
        "        PARAM_PHASE_DEFINITIONS (dict): パラメータシート作成のフェーズ定義。\n",
        "        CONSTRUCTION_PHASE_DEFINITIONS (dict): 構築準備のフェーズ定義。\n",
        "        KUKAN_TO_PHASES_MAP (dict): 区分ごとのフェーズ定義マッピング。\n",
        "        PROCESS_DEFINITIONS (dict): 進捗状況シート用のプロセス定義。\n",
        "        DOCUMENT_ORDER (list): 設計書名の表示順リスト。\n",
        "        SHEET_STYLES (dict): シートごとのスタイルと集計設定。\n",
        "    \"\"\"\n",
        "    # --- ファイルパス ---\n",
        "    FILES = {\n",
        "        'online_progress': 'テレ為替基盤_内部スケジュール(ID)_(オンラインのみ)20250625a.xlsx',\n",
        "        'other_progress': 'テレ為替基盤_内部スケジュール(ID)サマリ_20250702.xlsx',\n",
        "        'issue_list': '詳細設計事前検討一覧_マージ版.xlsx',\n",
        "        'construction_schedule': 'テレ為替基盤_構築準備スケジュール_20250908.xlsx'\n",
        "    }\n",
        "\n",
        "    # --- シート名定義 ---\n",
        "    SHEET_NAMES = {\n",
        "        \"progress\": \"進捗状況\",\n",
        "        \"issue\": \"課題状況\",\n",
        "        \"new_transfer\": \"新ファイル転送進捗状況\",\n",
        "        \"missing_page\": \"頁数未設定\",\n",
        "        \"construction_prep\": \"構築準備\"\n",
        "    }\n",
        "\n",
        "    # --- 読み込み設定 ---\n",
        "    LOAD_CONFIG = {\n",
        "        'START_ROW_ONLINE': 14, 'START_ROW': 54, 'START_COLUMN': 3, 'END_COLUMN': 14,\n",
        "        'START_COLUMN_NEW_FILE_TRANSFER': 2, 'END_COLUMN_NEW_FILE_TRANSFER': 13,\n",
        "        'START_ROW_ISSUE_LIST': 5, 'PROGRESS_SHEET_NAME': 'テレ為替',\n",
        "        'NEW_FILE_TRANSFER_PROGRESS_SHEET_NAME': '新ファイル転送',\n",
        "        'CONSTRUCTION_PREP_SHEET_NAME': 0,\n",
        "        'START_ROW_CONSTRUCTION_PREP': 14,\n",
        "        'USE_COLS_CONSTRUCTION_PREP': 'D:N'\n",
        "    }\n",
        "\n",
        "    COL_NAMES_CONSTRUCTION_PREP = [\n",
        "        '区分','対象','作業項目','開始予定日','終了予定日','開始実績日',\n",
        "        '終了実績日','予定頁数','実績頁数','担当','状況'\n",
        "    ]\n",
        "\n",
        "    # --- 区分ごとのフェーズ定義 ---\n",
        "    PARAM_PHASE_DEFINITIONS = {\n",
        "        '準備フェーズ': ['雛形/パラメータ決定', '情報収集', '雛形(PV)B.U.', '課題抽出/QA発出',  '課題抽出/QA発出（中断）', '課題抽出/QA発出(再開）', '非互換影響確認', '雛形(PV)認識合わせ', 'ヒアリング項目作成', '非互換確認', '環境準備', 'APヒアリング', '雛形入手or作成', '(雛形すり合わせ）', '非互換確認／修正', '雛形（集配信定義除く）B.U.', '雛形作成'],\n",
        "        'パラメータシート作成フェーズ': ['パラメータ仮埋め', 'パラメータ仮埋め（コア）','パラメータシート修正', 'パラメタ見直し', '非互換/変更要件反映', '中間すり合わせ', 'パラメータ見直し', 'パラメータ仮決め', 'パラメータ仮決め（ジョブ除く）', 'パラメータ入力', '作成', 'パラメータ修正'],\n",
        "        'T内Revフェーズ': ['T内Rev', 'T'],\n",
        "        'GLRevフェーズ': ['GLRev', 'GL'],\n",
        "        'デザインRevフェーズ': ['デザインRev'],\n",
        "        'コア→モア、他センタ展開フェーズ': ['コア→モア、他センタ展開']\n",
        "    }\n",
        "\n",
        "    CONSTRUCTION_PHASE_DEFINITIONS = {\n",
        "        '構築手順、定義体作成フェーズ': ['構築手順、定義体作成'],\n",
        "        'T内Revフェーズ': ['T内Rev', 'T']\n",
        "    }\n",
        "\n",
        "    KUKAN_TO_PHASES_MAP = {\n",
        "        \"パラメータシート作成\": PARAM_PHASE_DEFINITIONS,\n",
        "        \"構築準備\": CONSTRUCTION_PHASE_DEFINITIONS\n",
        "    }\n",
        "\n",
        "    # --- 進捗状況シート用のプロセス定義 ---\n",
        "    PROCESS_DEFINITIONS = {\n",
        "        'writing': ['設計書執筆（骨子への下書き）', '設計書執筆（別紙作成下書き）','設計書修正'],\n",
        "        'finalize': ['清書(PullRequest依頼まで)', '清書(PullRequest依頼⇒修正含む)', '設計書執筆（MarkDown清書PullRequest依頼まで）&確認結果修正'],\n",
        "        'team_review': ['T内レビュー', 'チーム内レビュー'], 'gl_review': ['GLレビュー'], 'psl_review': ['PSLレビュー']\n",
        "    }\n",
        "\n",
        "    # --- ドキュメント順序 ---\n",
        "    DOCUMENT_ORDER = [\n",
        "        'オンライン処理方式詳細設計書','データベース詳細設計書','帳票処理方式詳細設計書','クラスタミドルウェア詳細設計書',\n",
        "        'セキュリティ詳細設計書','システム運転管理詳細設計書','システム監視方式詳細設計書','ジョブネット設計規約',\n",
        "        'バックアップ処理方式詳細設計書','リリース管理方式詳細設計書','ログ管理方式詳細設計書','処理実績管理方式詳細設計書',\n",
        "        'システム運用様式','OS詳細設計書','HW設備詳細設計書','ストレージ詳細設計書','ネットワーク詳細設計書',\n",
        "        '仮想化基盤詳細設計書','端末詳細設計書','バッチ処理方式詳細設計書','バックアップ方式詳細設計書',\n",
        "        '新F転(オープンサーバ/AP基盤編)','新F転(AP基盤編)','新F転(オープンサーバ)','共通'\n",
        "    ]\n",
        "\n",
        "    # --- シートごとのスタイルと集計設定 ---\n",
        "    SHEET_STYLES = {\n",
        "        SHEET_NAMES[\"progress\"]: {\n",
        "            \"column_widths\": {'A:A': 34.3, 'B:F': 11.4, 'G:H': 14.4, 'I:O': 11.4, 'P:Q': 14.4, 'R:AC': 11.4},\n",
        "            \"sum_cols\": [1, 2, 3, 5, 8, 9, 11, 12, 14, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
        "            \"ratio_cols\": [(3, 1, 4), (9, 8, 10), (12, 1, 13), (18, 17, 19)],\n",
        "            \"diff_cols\": list(range(1, 6)) + list(range(8, 15)) + list(range(17, 29)),\n",
        "            \"percent_cols\": [4, 10, 13, 19], \"date_cols\": [6, 15],\n",
        "            \"highlight_rows\": {\"column\": \"設計書名\", \"values\": [\"帳票処理方式詳細設計書\", \"システム運用様式\", \"端末詳細設計書\"]}\n",
        "        },\n",
        "        SHEET_NAMES[\"issue\"]: {\n",
        "            \"column_widths\": {'A:A': 35, 'B:E': 15, 'F:H': 25}, \"sum_cols\": [1, 2, 3, 4], \"ratio_cols\": [], \"diff_cols\": [1, 2, 3, 4]\n",
        "        },\n",
        "        SHEET_NAMES[\"new_transfer\"]: {\n",
        "            \"column_widths\": {'A:A': 34.3, 'B:K': 11.4, 'L:T': 11.4}, \"sum_cols\": [1, 2, 3, 5, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18],\n",
        "            \"ratio_cols\": [(3, 1, 4), (9, 8, 10)], \"diff_cols\": list(range(1, 6)) + list(range(8, 11)) + list(range(11, 19)),\n",
        "            \"percent_cols\": [4, 10], \"date_cols\": [6]\n",
        "        },\n",
        "        SHEET_NAMES[\"missing_page\"]: {\n",
        "            \"column_widths\": {'A:A': 30, 'B:B': 30, 'C:G': 15, 'H:I': 12, 'J:K': 15}, \"date_cols\": [3, 4, 5, 6]\n",
        "        }\n",
        "    }\n",
        "\n",
        "# ==============================================================================\n",
        "# データ抽出・加工・集計系の関数\n",
        "# ==============================================================================\n",
        "def extract_columns_by_range(dataframe: pd.DataFrame, start_col_index: int, end_col_index: int) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    指定した列範囲をDataFrameから抽出し、列名を標準化して返します。\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): 元データフレーム。\n",
        "        start_col_index (int): 抽出開始列インデックス（0始まり）。\n",
        "        end_col_index (int): 抽出終了列インデックス（0始まり、endは含まない）。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 抽出・整形済みのデータフレーム。\n",
        "\n",
        "    Raises:\n",
        "        IndexError: インデックスが範囲外または不正な場合。\n",
        "    \"\"\"\n",
        "    num_cols = len(dataframe.columns)\n",
        "    if not (0 <= start_col_index < num_cols and 0 <= end_col_index <= num_cols and start_col_index < end_col_index):\n",
        "        raise IndexError(f\"列のインデックスが範囲外または不正です。start:{start_col_index}, end:{end_col_index}, total:{num_cols}\")\n",
        "    extracted_df = dataframe.iloc[:, start_col_index:end_col_index]\n",
        "    new_column_names = ['document_name','process_name','work_item','start_date_planned','end_date_planned','start_date_actual','end_date_actual','page_planned','page_actual','assignee','status']\n",
        "    extracted_df.columns = new_column_names\n",
        "    return extracted_df\n",
        "\n",
        "def extract_columns_by_range_issue(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    課題管理用のDataFrameから不連続な範囲の列を抽出し、新しい列名を付けて返します。\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): 元データフレーム。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 抽出・整形済みの課題データフレーム。\n",
        "\n",
        "    Raises:\n",
        "        ValueError: 抽出された列数と新しい列名の数が一致しない場合。\n",
        "    \"\"\"\n",
        "    target_indices = np.r_[0:5, 10:20]\n",
        "    extracted_df = dataframe.iloc[:, target_indices]\n",
        "    new_column_names = ['検討項目分類','課題番号','記入日','起票者','対象ドキュメント','完了予定日','優先度','難易度','Ｇ間調整','他Ｇヒアリング有無','完了予定の見通し','着手日','完了日','対応者','完了']\n",
        "    if len(new_column_names) != len(extracted_df.columns): raise ValueError(\"抽出された列数と新しい列名の数が一致しません。\")\n",
        "    extracted_df.columns = new_column_names\n",
        "    return extracted_df\n",
        "\n",
        "def get_unique_values_from_column_with_start_row(dataframe: pd.DataFrame, column_index: int, start_row_index: int = 0) -> list:\n",
        "    \"\"\"\n",
        "    DataFrameの指定列から、NaNや空文字列を除いた一意な値のリストを取得します。\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): 元データフレーム。\n",
        "        column_index (int): 対象列インデックス。\n",
        "        start_row_index (int, optional): 開始行インデックス。デフォルトは0。\n",
        "\n",
        "    Returns:\n",
        "        list: 一意な値のリスト。範囲外の場合は空リスト。\n",
        "    \"\"\"\n",
        "    if not (0 <= column_index < len(dataframe.columns) and 0 <= start_row_index < len(dataframe)):\n",
        "        print(f\"警告: get_unique_valuesのインデックスが範囲外です。col:{column_index}, row:{start_row_index}\")\n",
        "        return []\n",
        "    series = dataframe.iloc[start_row_index:, column_index]\n",
        "    cleaned_series = series.dropna()\n",
        "    if pd.api.types.is_string_dtype(cleaned_series):\n",
        "        cleaned_series = cleaned_series[cleaned_series.astype(str).str.strip() != '']\n",
        "    return cleaned_series.unique().tolist()\n",
        "\n",
        "def load_data_to_dataframe(file_path: str, start_row: int, sheet_name: Union[str, int] = 0, usecols: Optional[str] = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    指定したExcelファイルまたはCSVファイルからデータを読み込み、DataFrameとして返します。\n",
        "\n",
        "    Args:\n",
        "        file_path (str): 読み込むファイルのパス。\n",
        "        start_row (int): 読み飛ばす行数（0始まり）。\n",
        "        sheet_name (Union[str, int], optional): シート名またはインデックス（Excelの場合）。デフォルトは0。\n",
        "        usecols (Optional[str], optional): 読み込む列範囲（例: 'A:D'）。デフォルトはNone。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 読み込んだデータフレーム。\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: ファイルが存在しない場合。\n",
        "        Exception: 読み込み時にエラーが発生した場合。\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path): raise FileNotFoundError(f\"エラー: ファイル '{file_path}' が見つかりません。\")\n",
        "    try:\n",
        "        return pd.read_excel(file_path, skiprows=start_row, sheet_name=sheet_name, usecols=usecols)\n",
        "    except Exception as e: raise Exception(f\"ファイル '{file_path}' の読み込み中にエラーが発生しました: {e}\")\n",
        "\n",
        "def analyze_document_tasks(target_df: pd.DataFrame) -> tuple:\n",
        "    \"\"\"\n",
        "    文書ごとの未完了タスクを分析し、遅延状況などを算出します。\n",
        "\n",
        "    Args:\n",
        "        target_df (pd.DataFrame): 対象となるタスクデータフレーム。\n",
        "\n",
        "    Returns:\n",
        "        tuple: (遅延タスク数, 遅延タスクのリスト, 最大遅延日数, 最新の完了予定日文字列)\n",
        "            遅延タスク数 (int): 期限を過ぎている未完了タスクの件数。\n",
        "            遅延タスクのリスト (list): 期限を過ぎている未完了タスクの辞書リスト。\n",
        "            最大遅延日数 (int): 最新の完了予定日と本日との差分（日数）。\n",
        "            最新の完了予定日文字列 (str): 最大の完了予定日（'YYYY-MM-DD'形式または未設定時の文字列）。\n",
        "    \"\"\"\n",
        "    if target_df.empty: return 0, [], 0, \"タスク未設定\"\n",
        "    active_statuses = ['未着手', '着手中', '対応中']\n",
        "    active_tasks_df = target_df[target_df['status'].isin(active_statuses)].copy()\n",
        "    if active_tasks_df.empty: return 0, [], 0, \"タスク完了済み\"\n",
        "    execution_date = pd.to_datetime('today').normalize()\n",
        "    end_dates = pd.to_datetime(active_tasks_df['end_date_planned'], format='%Y-%m-%d', errors='coerce')\n",
        "    max_date = end_dates.max()\n",
        "    latest_date_str = max_date.strftime('%Y-%m-%d') if pd.notna(max_date) else \"完了予定日未設定\"\n",
        "    delay_days = (max_date.date() - execution_date.date()).days if pd.notna(max_date) else 0\n",
        "    is_overdue = end_dates < execution_date\n",
        "    overdue_count = is_overdue.sum()\n",
        "    overdue_tasks = active_tasks_df[is_overdue].to_dict('records')\n",
        "    return overdue_count, overdue_tasks, delay_days, latest_date_str\n",
        "\n",
        "def extract_delayed_tasks(input_df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    DataFrameから完了予定日を過ぎた未完了タスクと、完了予定日が未設定（NaT）の行を抽出します。\n",
        "\n",
        "    Args:\n",
        "        input_df (pd.DataFrame): 元データフレーム。\n",
        "\n",
        "    Returns:\n",
        "        tuple: (遅延タスクDataFrame, 完了予定日NaT行DataFrame)\n",
        "            遅延タスクDataFrame (pd.DataFrame): 完了予定日を過ぎた未完了タスク。\n",
        "            完了予定日NaT行DataFrame (pd.DataFrame): 完了予定日が未設定の行。\n",
        "    \"\"\"\n",
        "    copy_df = input_df.copy()\n",
        "    copy_df['完了予定日'] = pd.to_datetime(copy_df['完了予定日'], format='%Y-%m-%d', errors='coerce')\n",
        "    today = pd.to_datetime('today').normalize()\n",
        "    is_valid_date = copy_df['完了予定日'].notna()\n",
        "    is_due = copy_df['完了予定日'] < today\n",
        "    is_incomplete = copy_df['完了'] != '完了'\n",
        "    delayed_tasks_df = copy_df[is_valid_date & is_due & is_incomplete].copy()\n",
        "    nat_rows_df = copy_df[copy_df['完了予定日'].isna()]\n",
        "    return delayed_tasks_df, nat_rows_df\n",
        "\n",
        "def load_and_prepare_progress_data(online_file: str, other_file: str, config: dict, sheet_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    進捗データファイル（オンライン・その他）を読み込み、指定範囲の列を抽出・結合して返します。\n",
        "\n",
        "    Args:\n",
        "        online_file (str): オンライン設計書進捗ファイルのパス。\n",
        "        other_file (str): その他設計書進捗ファイルのパス。\n",
        "        config (dict): 読み込み設定辞書（開始行・列など）。\n",
        "        sheet_name (str): 読み込むシート名。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 結合・整形済みの進捗データフレーム。\n",
        "    \"\"\"\n",
        "    print(\"進捗データの読み込みと準備を開始...\")\n",
        "    online_df = load_data_to_dataframe(online_file, config['START_ROW_ONLINE'], sheet_name)\n",
        "    other_df = load_data_to_dataframe(other_file, config['START_ROW'], sheet_name)\n",
        "    extracted_online_df = extract_columns_by_range(online_df, config['START_COLUMN'], config['END_COLUMN'])\n",
        "    extracted_other_df = extract_columns_by_range(other_df, config['START_COLUMN'], config['END_COLUMN'])\n",
        "    all_df = pd.concat([extracted_online_df, extracted_other_df], axis=0, ignore_index=True)\n",
        "    print(\"進捗データの準備が完了しました。\")\n",
        "    return all_df\n",
        "\n",
        "def load_and_prepare_new_file_transfer_data(other_file: str, config: dict, sheet_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    新ファイル転送進捗データを読み込み、指定範囲の列を抽出して返します。\n",
        "\n",
        "    Args:\n",
        "        other_file (str): 新ファイル転送進捗ファイルのパス。\n",
        "        config (dict): 読み込み設定辞書。\n",
        "        sheet_name (str): 読み込むシート名。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 整形済みの新ファイル転送進捗データフレーム。\n",
        "    \"\"\"\n",
        "    print(\"新ファイル転送進捗データの読み込みと準備を開始...\")\n",
        "    other_df = load_data_to_dataframe(other_file, config['START_ROW_ONLINE'], sheet_name)\n",
        "    extracted_df = extract_columns_by_range(other_df, config['START_COLUMN_NEW_FILE_TRANSFER'], config['END_COLUMN_NEW_FILE_TRANSFER'])\n",
        "    print(\"新ファイル転送進捗データの準備が完了しました。\")\n",
        "    return extracted_df\n",
        "\n",
        "def load_and_prepare_issue_data(issue_file: str, config: dict) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    課題管理ファイルを読み込み、必要な列を抽出・整形して返します。\n",
        "\n",
        "    Args:\n",
        "        issue_file (str): 課題管理ファイルのパス。\n",
        "        config (dict): 読み込み設定辞書。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 整形済みの課題データフレーム。\n",
        "    \"\"\"\n",
        "    print(\"課題データの読み込みと準備を開始...\")\n",
        "    issue_df_raw = load_data_to_dataframe(issue_file, config['START_ROW_ISSUE_LIST'], '課題一覧')\n",
        "    intermediate_df = extract_columns_by_range_issue(issue_df_raw)\n",
        "    print(\"課題データの準備が完了しました。\")\n",
        "    return intermediate_df\n",
        "\n",
        "def load_and_prepare_construction_data(file_path: str, config: dict, col_names: list) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    構築準備スケジュールデータを読み込み、前処理を行いDataFrameとして返します。\n",
        "\n",
        "    Args:\n",
        "        file_path (str): 構築準備スケジュールファイルのパス。\n",
        "        config (dict): 読み込み設定辞書。\n",
        "        col_names (list): 設定する列名リスト。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 前処理済みの構築準備データフレーム。\n",
        "\n",
        "    Raises:\n",
        "        ValueError: 読み込んだ列数と設定列名の数が一致しない場合。\n",
        "    \"\"\"\n",
        "    print(\"構築準備スケジュールデータの読み込みと準備を開始...\")\n",
        "    df = load_data_to_dataframe(\n",
        "        file_path, config['START_ROW_CONSTRUCTION_PREP'],\n",
        "        config['CONSTRUCTION_PREP_SHEET_NAME'], config['USE_COLS_CONSTRUCTION_PREP']\n",
        "    )\n",
        "    df.dropna(how='all', inplace=True)\n",
        "    if len(col_names) == len(df.columns): df.columns = col_names\n",
        "    else: raise ValueError(f\"読み込んだ列数({len(df.columns)})と設定列名の数({len(col_names)})が一致しません。\")\n",
        "\n",
        "    date_cols = ['開始予定日', '終了予定日', '開始実績日', '終了実績日']\n",
        "    for col in date_cols: df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "\n",
        "    numeric_cols = ['予定頁数', '実績頁数']\n",
        "    for col in numeric_cols: df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "\n",
        "    print(\"構築準備スケジュールデータの準備が完了しました。\")\n",
        "    return df\n",
        "\n",
        "def extract_missing_page_tasks(online_file: str, other_file: str, config: dict, sheet_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    進捗ファイルから、完了済みかつ予定頁数または実績頁数が未設定のタスクを抽出します。\n",
        "\n",
        "    Args:\n",
        "        online_file (str): オンライン設計書進捗ファイルのパス。\n",
        "        other_file (str): その他設計書進捗ファイルのパス。\n",
        "        config (dict): 読み込み設定辞書。\n",
        "        sheet_name (str): 読み込むシート名。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 頁数または実績未設定の完了タスクのみを含むDataFrame。\n",
        "    \"\"\"\n",
        "    print(\"頁数/実績未設定の完了タスク抽出を開始...\")\n",
        "    combined_df = load_and_prepare_progress_data(online_file, other_file, config, sheet_name)\n",
        "    target_processes = {\n",
        "        \"清書(PullRequest依頼⇒修正含む)\", \"設計書執筆（骨子への下書き）\", \"清書(PullRequest依頼まで)\",\n",
        "        \"設計書執筆（別紙作成下書き）\", \"設計書執筆（MarkDown清書PullRequest依頼まで）&確認結果修正\"\n",
        "    }\n",
        "    condition1 = combined_df['process_name'].isin(target_processes)\n",
        "    condition2 = combined_df['status'] == '完了'\n",
        "    page_planned_is_na = pd.to_numeric(combined_df['page_planned'], errors='coerce').isna()\n",
        "    page_actual_is_na = pd.to_numeric(combined_df['page_actual'], errors='coerce').isna()\n",
        "    condition3 = page_planned_is_na | page_actual_is_na\n",
        "    filtered_df = combined_df[condition1 & condition2 & condition3].copy()\n",
        "    print(f\"頁数/実績未設定の完了タスクを {len(filtered_df)} 件抽出しました。\")\n",
        "    return filtered_df\n",
        "\n",
        "def summarize_document_progress(progress_df: pd.DataFrame, process_definitions: dict, include_finalize: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    進捗データから、設計書ごとの進捗状況を集計します。\n",
        "\n",
        "    Args:\n",
        "        progress_df (pd.DataFrame): 進捗データフレーム。\n",
        "        process_definitions (dict): プロセス定義（執筆・清書・レビュー等の分類）。\n",
        "        include_finalize (bool, optional): 清書プロセスも集計する場合はTrue。デフォルトはTrue。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 設計書ごとの進捗集計結果データフレーム。\n",
        "    \"\"\"\n",
        "    print(f\"進捗状況の集計を開始 (清書集計: {include_finalize})...\")\n",
        "    document_list = get_unique_values_from_column_with_start_row(progress_df, 0, 0)\n",
        "    row_list = []\n",
        "    for document_name in document_list:\n",
        "        per_doc_df = progress_df[progress_df['document_name'] == document_name]\n",
        "        per_doc_writing_df = per_doc_df[per_doc_df['process_name'].isin(process_definitions['writing'])]\n",
        "        per_doc_team_review_df = per_doc_df[per_doc_df['process_name'].isin(process_definitions['team_review'])]\n",
        "        per_doc_gl_review_df = per_doc_df[per_doc_df['process_name'].isin(process_definitions['gl_review'])]\n",
        "        per_doc_psl_review_df = per_doc_df[per_doc_df['process_name'].isin(process_definitions['psl_review'])]\n",
        "        total = len(per_doc_writing_df)\n",
        "        status_counts = per_doc_writing_df['status'].value_counts()\n",
        "        writing_ongoing = status_counts.get('着手中', 0) + status_counts.get('対応中', 0)\n",
        "        writing_complete = status_counts.get('完了', 0)\n",
        "        copy_writing_df = per_doc_writing_df.copy()\n",
        "        copy_writing_df['page_planned_numeric'] = pd.to_numeric(copy_writing_df['page_planned'], errors='coerce')\n",
        "        copy_writing_df['page_actual_numeric'] = pd.to_numeric(copy_writing_df['page_actual'], errors='coerce')\n",
        "        total_pages_planned = copy_writing_df['page_planned_numeric'].sum()\n",
        "        total_pages_actual = copy_writing_df['page_actual_numeric'].sum()\n",
        "        writing_overdue, _, delay_date_count, latest_expected_completion_date = analyze_document_tasks(copy_writing_df)\n",
        "        new_row = {'設計書名': document_name,'執筆全量': total, '執筆着手中': writing_ongoing, '執筆完了': writing_complete,'執筆消化率': f\"{(writing_complete / total) if total != 0 else 0.0:.1%}\",'執筆遅延': writing_overdue, '執筆完了予定日': latest_expected_completion_date, '執筆完了予定日に対する遅れ': delay_date_count,'執筆予定頁数': total_pages_planned, '執筆実績頁数': total_pages_actual,'執筆頁消化率': f\"{(total_pages_actual / total_pages_planned) if total_pages_planned != 0 else 0.0:.1%}\",}\n",
        "        if include_finalize:\n",
        "            per_doc_finalize_df = per_doc_df[per_doc_df['process_name'].isin(process_definitions['finalize'])]\n",
        "            status_counts_finalize = per_doc_finalize_df['status'].value_counts()\n",
        "            finalize_ongoing = status_counts_finalize.get('着手中', 0)\n",
        "            finalize_complete = status_counts_finalize.get('完了', 0)\n",
        "            copy_finalize_df = per_doc_finalize_df.copy()\n",
        "            copy_finalize_df['page_planned_numeric'] = pd.to_numeric(copy_finalize_df['page_planned'], errors='coerce')\n",
        "            copy_finalize_df['page_actual_numeric'] = pd.to_numeric(copy_finalize_df['page_actual'], errors='coerce')\n",
        "            total_pages_planned_finalize = copy_finalize_df['page_planned_numeric'].sum()\n",
        "            total_pages_actual_finalize = copy_finalize_df['page_actual_numeric'].sum()\n",
        "            finalize_overdue, _, finalize_delay_date_count, finalize_latest_date = analyze_document_tasks(copy_finalize_df)\n",
        "            new_row.update({'清書着手中': finalize_ongoing, '清書完了': finalize_complete,'清書消化率': f\"{(finalize_complete / len(per_doc_finalize_df)) if len(per_doc_finalize_df) != 0 else 0.0:.1%}\",'清書遅延': finalize_overdue, '清書完了予定日': finalize_latest_date, '清書完了予定日に対する遅れ': finalize_delay_date_count,'清書予定頁数': total_pages_planned_finalize, '清書実績頁数': total_pages_actual_finalize,'清書頁消化率': f\"{(total_pages_actual_finalize / total_pages_planned_finalize) if total_pages_planned_finalize != 0 else 0.0:.1%}\",})\n",
        "        new_row.update({'T内RV中': per_doc_team_review_df['status'].value_counts().get('着手中', 0),'T内RV完了': per_doc_team_review_df['status'].value_counts().get('完了', 0),'T内RV全量': len(per_doc_team_review_df),'GL RV中': per_doc_gl_review_df['status'].value_counts().get('着手中', 0),'GL RV完了': per_doc_gl_review_df['status'].value_counts().get('完了', 0),'GL RV全量': len(per_doc_gl_review_df),'PSL RV中': per_doc_psl_review_df['status'].value_counts().get('着手中', 0),'PSL RV完了': per_doc_psl_review_df['status'].value_counts().get('完了', 0),'PSL RV全量': len(per_doc_psl_review_df),})\n",
        "        row_list.append(new_row)\n",
        "    print(\"進捗状況の集計が完了しました。\")\n",
        "    return pd.DataFrame(row_list)\n",
        "\n",
        "def summarize_issues(issue_df: pd.DataFrame, custom_order: list) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    課題データから、設計書ごとの課題状況を集計・ソートします。\n",
        "\n",
        "    Args:\n",
        "        issue_df (pd.DataFrame): 課題データフレーム。\n",
        "        custom_order (list): 設計書名の表示順リスト。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 設計書ごとの課題集計・ソート済みデータフレーム。\n",
        "    \"\"\"\n",
        "    print(\"課題状況の集計を開始...\")\n",
        "    document_list_issue = get_unique_values_from_column_with_start_row(issue_df, 4, 0)\n",
        "    issue_list = []\n",
        "    for document_name in document_list_issue:\n",
        "        per_doc_df = issue_df[issue_df['対象ドキュメント'] == document_name].copy()\n",
        "        per_doc_df['完了'] = per_doc_df['完了'].str.replace(r'\\s+', '', regex=True)\n",
        "        per_doc_incomplete_df = per_doc_df[per_doc_df['完了'] != '完了']\n",
        "        overdue_task_df, nat_rows_df = extract_delayed_tasks(per_doc_incomplete_df)\n",
        "        new_row = {'設計書名': document_name,'設計書ごと課題全量': len(per_doc_df),'課題着手中': len(per_doc_incomplete_df[per_doc_incomplete_df['完了'].isin(['ヒアリングシート・QA発行Ｇ間資料待ち', '検討中'])]),'完了済み': len(per_doc_df) - len(per_doc_incomplete_df),'遅延': len(overdue_task_df['課題番号'].unique()),'完了予定日空白課題リスト': nat_rows_df['課題番号'].tolist(),'完了予定日超過課題リスト': overdue_task_df['課題番号'].unique().tolist(),'完了列空白課題リスト': per_doc_incomplete_df[per_doc_incomplete_df['完了'].isna()]['課題番号'].tolist(),}\n",
        "        issue_list.append(new_row)\n",
        "    result_issue_df = pd.DataFrame(issue_list)\n",
        "    existing_values = result_issue_df['設計書名'].unique()\n",
        "    filtered_order = [item for item in custom_order if item in existing_values]\n",
        "    result_issue_df['設計書名'] = pd.Categorical(result_issue_df['設計書名'], categories=filtered_order, ordered=True)\n",
        "    issue_df_sorted = result_issue_df.sort_values('設計書名')\n",
        "    print(\"課題状況の集計が完了しました。\")\n",
        "    return issue_df_sorted\n",
        "\n",
        "def process_construction_prep_data(prep_df: pd.DataFrame, kukan_to_phases_map: dict) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    構築準備データを区分ごとにグループ化し、集計します。\n",
        "\n",
        "    Args:\n",
        "        prep_df (pd.DataFrame): 構築準備データフレーム。\n",
        "        kukan_to_phases_map (dict): 区分ごとのフェーズ定義マッピング。\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: 区分・対象・フェーズごとに集計された構築準備データフレーム。\n",
        "\n",
        "    Raises:\n",
        "        ValueError: 未定義の作業項目が存在する場合。\n",
        "    \"\"\"\n",
        "    print(\"構築準備データの集計処理を開始...\")\n",
        "    all_grouped_dfs = []\n",
        "\n",
        "    for kukan, phase_definitions in kukan_to_phases_map.items():\n",
        "        kukan_df = prep_df[prep_df['区分'] == kukan].copy()\n",
        "        if kukan_df.empty:\n",
        "            print(f\"INFO: 区分「{kukan}」のデータが見つかりませんでした。\")\n",
        "            continue\n",
        "\n",
        "        item_to_phase_map = {item.strip(): phase for phase, items in phase_definitions.items() for item in items}\n",
        "        kukan_df['フェーズ'] = kukan_df['作業項目'].str.strip().map(item_to_phase_map)\n",
        "\n",
        "        unmapped_items = kukan_df[kukan_df['フェーズ'].isna()]['作業項目'].unique()\n",
        "        if len(unmapped_items) > 0:\n",
        "            unmapped_str = \", \".join(f\"'{item}'\" for item in unmapped_items)\n",
        "            raise ValueError(f\"区分「{kukan}」で未定義の作業項目が検出されました: {unmapped_str}\")\n",
        "\n",
        "        agg_rules = {'開始予定日': 'min', '終了予定日': 'max', '予定頁数': 'max', '実績頁数': 'min'}\n",
        "        grouped = kukan_df.groupby(['区分', '対象', 'フェーズ']).agg(agg_rules)\n",
        "        all_grouped_dfs.append(grouped)\n",
        "\n",
        "    if not all_grouped_dfs:\n",
        "        print(\"WARNING: 処理対象となる区分のデータがありませんでした。\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    final_df = pd.concat(all_grouped_dfs)\n",
        "    print(\"構築準備データの集計処理が完了しました。\")\n",
        "    return final_df\n",
        "\n",
        "def read_latest_past_totals(pattern: str) -> Dict[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    昨日以前の最新レポートファイルを探し、存在する全シートから「合計」行を読み込みます。\n",
        "\n",
        "    Args:\n",
        "        pattern (str): ファイル検索パターン（例: '*-進捗課題状況.xlsx'）。\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, pd.DataFrame]: シート名をキー、「合計」行のみ抽出したDataFrameを値とする辞書。\n",
        "                                 ファイルが見つからない場合は空辞書を返します。\n",
        "\n",
        "    Raises:\n",
        "        例外発生時はエラーメッセージを出力し、空辞書を返します。\n",
        "    \"\"\"\n",
        "    today = date.today()\n",
        "    all_files = glob.glob(pattern)\n",
        "    file_date_list = []\n",
        "    for f in all_files:\n",
        "        if m := re.search(r'(\\d{4}-\\d{2}-\\d{2})', f):\n",
        "            try:\n",
        "                file_dt = datetime.strptime(m.group(1), \"%Y-%m-%d\").date()\n",
        "                if file_dt < today: file_date_list.append((file_dt, f))\n",
        "            except ValueError: continue\n",
        "    if not file_date_list:\n",
        "        print(\"⚠️ 読み込み対象となる昨日以前のファイルが見つかりませんでした。\")\n",
        "        return {}\n",
        "\n",
        "    latest_file = max(file_date_list, key=lambda x: x[0])[1]\n",
        "    print(f\"✅ 過去レポート読み込み: {latest_file}\")\n",
        "\n",
        "    try:\n",
        "        previous_dfs = pd.read_excel(latest_file, sheet_name=None)\n",
        "        return {\n",
        "            sheet_name: df[df.iloc[:, 0] == '合計'].copy()\n",
        "            for sheet_name, df in previous_dfs.items()\n",
        "            if not df.empty and df.iloc[:, 0].astype(str).str.contains('合計').any()\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 過去レポートの読み込み中にエラーが発生しました: {e}\")\n",
        "        return {}\n",
        "\n",
        "# ==============================================================================\n",
        "# Excel出力関連クラス (リファクタリング適用)\n",
        "# ==============================================================================\n",
        "\n",
        "class SheetWriter:\n",
        "    \"\"\"Excelシート書き込み処理の設計図（基底クラス）\"\"\"\n",
        "    def __init__(self, workbook: xlsxwriter.Workbook, config: ReportConfig):\n",
        "        self.workbook = workbook\n",
        "        self.config = config\n",
        "\n",
        "    def write(self, sheet_name: str, data: pd.DataFrame, previous_total: Optional[pd.DataFrame] = None):\n",
        "        raise NotImplementedError(\"This method should be implemented by subclasses.\")\n",
        "\n",
        "class StandardSheetWriter(SheetWriter):\n",
        "    \"\"\"標準的なフォーマット（データ+合計行+前回比）でシートを書き込むクラス\"\"\"\n",
        "    def write(self, sheet_name: str, data: pd.DataFrame, previous_total: Optional[pd.DataFrame] = None):\n",
        "        print(f\"「{sheet_name}」を標準フォーマットで書き込み中...\")\n",
        "        worksheet = self.workbook.add_worksheet(sheet_name)\n",
        "        sheet_config = self.config.SHEET_STYLES.get(sheet_name, {})\n",
        "        if not sheet_config:\n",
        "            print(f\"WARNING: シート「{sheet_name}」のスタイル設定が見つかりません。\")\n",
        "            return\n",
        "\n",
        "        formats = self._apply_formats(worksheet, sheet_config)\n",
        "\n",
        "        # 日付列を変換\n",
        "        date_cols_indices = sheet_config.get(\"date_cols\", [])\n",
        "        if date_cols_indices:\n",
        "            date_cols_names = [data.columns[i] for i in date_cols_indices if i < len(data.columns)]\n",
        "            preserved_strings = {\"タスク未設定\", \"タスク完了済み\", \"完了予定日未設定\"}\n",
        "            def smart_date_converter(value):\n",
        "                return value if value in preserved_strings or pd.isna(value) else pd.to_datetime(value, errors='coerce')\n",
        "            for col in date_cols_names:\n",
        "                if col in data.columns: data[col] = data[col].apply(smart_date_converter)\n",
        "\n",
        "        # ヘッダー書き込み\n",
        "        for col_idx, col_name in enumerate(data.columns):\n",
        "            worksheet.write(0, col_idx, col_name, formats['header'])\n",
        "\n",
        "        # データ書き込み\n",
        "        highlight_config = sheet_config.get(\"highlight_rows\")\n",
        "        highlight_col = highlight_config[\"column\"] if highlight_config else None\n",
        "        highlight_vals = set(highlight_config[\"values\"]) if highlight_config else set()\n",
        "        for row_idx, row_data in enumerate(data.itertuples(index=False)):\n",
        "            excel_row_idx = row_idx + 1\n",
        "            is_highlight_row = highlight_col and getattr(row_data, highlight_col, None) in highlight_vals\n",
        "            for col_idx, cell_value in enumerate(row_data):\n",
        "                is_date_col = col_idx in date_cols_indices\n",
        "                cell_format = formats['gray_bkg_date'] if is_highlight_row and is_date_col else \\\n",
        "                              formats['gray_bkg'] if is_highlight_row else \\\n",
        "                              formats['date'] if is_date_col else formats['default']\n",
        "                if not pd.api.types.is_scalar(cell_value): worksheet.write_string(excel_row_idx, col_idx, str(cell_value), cell_format)\n",
        "                elif pd.isna(cell_value) or (isinstance(cell_value, pd.Timestamp) and pd.isna(cell_value)): worksheet.write_blank(excel_row_idx, col_idx, None, cell_format)\n",
        "                else: worksheet.write(excel_row_idx, col_idx, cell_value, cell_format)\n",
        "\n",
        "        # 合計行と前回比行を追加\n",
        "        num_data_rows = len(data)\n",
        "        if \"sum_cols\" in sheet_config:\n",
        "            total_row_idx = self._add_total_row(worksheet, num_data_rows, formats, sheet_config)\n",
        "            self._add_comparison_rows(worksheet, total_row_idx, previous_total, formats, sheet_config)\n",
        "\n",
        "    def _apply_formats(self, worksheet, sheet_config: dict) -> dict:\n",
        "        for col_range, width in sheet_config.get(\"column_widths\", {}).items():\n",
        "            worksheet.set_column(col_range, width)\n",
        "        base_props = {'valign': 'vcenter', 'align': 'center', 'text_wrap': True}\n",
        "        worksheet.set_row(0, 41)\n",
        "        return {\n",
        "            'header': self.workbook.add_format({**base_props, 'bold': True, 'bg_color': '#DDEBF7'}),\n",
        "            'default': self.workbook.add_format(base_props), 'bold': self.workbook.add_format({**base_props, 'bold': True}),\n",
        "            'percent': self.workbook.add_format({**base_props, 'num_format': '0.0%'}),\n",
        "            'percent_detailed': self.workbook.add_format({**base_props, 'num_format': '0.000%'}),\n",
        "            'gray_bkg': self.workbook.add_format({**base_props, 'bg_color': '#D9D9D9'}),\n",
        "            'total': self.workbook.add_format({**base_props, 'bold': True, 'bg_color': '#E2F0D9'}),\n",
        "            'total_percent': self.workbook.add_format({**base_props, 'bold': True, 'bg_color': '#E2F0D9', 'num_format': '0.0%'}),\n",
        "            'date': self.workbook.add_format({**base_props, 'num_format': 'yyyy-mm-dd'}),\n",
        "            'gray_bkg_date': self.workbook.add_format({**base_props, 'bg_color': '#D9D9D9', 'num_format': 'yyyy-mm-dd'}),\n",
        "        }\n",
        "\n",
        "    def _add_total_row(self, worksheet, num_data_rows: int, formats: dict, sheet_config: dict) -> int:\n",
        "        total_row_idx = num_data_rows + 1\n",
        "        total_row_excel_num = total_row_idx + 1\n",
        "        worksheet.set_row(total_row_idx, None, formats['total'])\n",
        "        worksheet.write(total_row_idx, 0, '合計', formats['total'])\n",
        "        for col_idx in sheet_config.get(\"sum_cols\", []):\n",
        "            col_letter = xlsxwriter.utility.xl_col_to_name(col_idx)\n",
        "            formula = f'=SUM({col_letter}2:{col_letter}{num_data_rows + 1})'\n",
        "            worksheet.write_formula(total_row_idx, col_idx, formula, formats['total'])\n",
        "        for num_idx, den_idx, out_idx in sheet_config.get(\"ratio_cols\", []):\n",
        "            num_col, den_col = xlsxwriter.utility.xl_col_to_name(num_idx), xlsxwriter.utility.xl_col_to_name(den_idx)\n",
        "            formula = f'=IFERROR({num_col}{total_row_excel_num}/{den_col}{total_row_excel_num},0)'\n",
        "            worksheet.write_formula(total_row_idx, out_idx, formula, formats['total_percent'])\n",
        "        return total_row_idx\n",
        "\n",
        "    def _add_comparison_rows(self, worksheet, total_row_idx: int, previous_total_row: pd.DataFrame, formats: dict, sheet_config: dict):\n",
        "        if previous_total_row is None or previous_total_row.empty:\n",
        "            print(f\"INFO: シート '{worksheet.name}' の前回集計データが見つからないため、前回比の行はスキップします。\")\n",
        "            return\n",
        "        diff_row_idx, prev_total_row_idx = total_row_idx + 1, total_row_idx + 2\n",
        "        total_row_excel_num, prev_total_row_excel_num = total_row_idx + 1, prev_total_row_idx + 1\n",
        "        worksheet.write(diff_row_idx, 0, '前回比', formats['bold'])\n",
        "        worksheet.write(prev_total_row_idx, 0, '前回集計の合計', formats['bold'])\n",
        "        percent_cols = sheet_config.get(\"percent_cols\", [])\n",
        "        prev_values = previous_total_row.iloc[0]\n",
        "        for i, value in enumerate(prev_values):\n",
        "            if i > 0 and pd.api.types.is_number(value) and np.isfinite(value):\n",
        "                 cell_format = formats['percent_detailed'] if i in percent_cols else formats['default']\n",
        "                 worksheet.write(prev_total_row_idx, i, value, cell_format)\n",
        "        for col_idx in sheet_config.get(\"diff_cols\", []):\n",
        "            col_letter = xlsxwriter.utility.xl_col_to_name(col_idx)\n",
        "            formula = f'={col_letter}{total_row_excel_num}-{col_letter}{prev_total_row_excel_num}'\n",
        "            cell_format = formats['percent_detailed'] if col_idx in percent_cols else formats['default']\n",
        "            worksheet.write_formula(diff_row_idx, col_idx, formula, cell_format)\n",
        "\n",
        "class ConstructionPrepSheetWriter(SheetWriter):\n",
        "    \"\"\"「構築準備」シートをカスタムレイアウトで書き込むクラス\"\"\"\n",
        "    def write(self, sheet_name: str, data: pd.DataFrame, previous_total: Optional[pd.DataFrame] = None):\n",
        "        print(f\"「{sheet_name}」シートのカスタム出力を開始...\")\n",
        "        worksheet = self.workbook.add_worksheet(sheet_name)\n",
        "        title_format = self.workbook.add_format({'bold': True, 'font_size': 18, 'valign': 'vcenter'})\n",
        "        phase_header_format = self.workbook.add_format({'bold': True, 'bg_color': '#DDEBF7', 'align': 'center', 'valign': 'vcenter', 'border': 1})\n",
        "        sub_header_format = self.workbook.add_format({'bold': True, 'bg_color': '#E2F0D9', 'align': 'center', 'valign': 'vcenter', 'border': 1, 'text_wrap': True})\n",
        "        target_format = self.workbook.add_format({'bold': True, 'align': 'left', 'valign': 'vcenter', 'border': 1, 'text_wrap': True})\n",
        "        default_format = self.workbook.add_format({'align': 'center', 'valign': 'vcenter', 'border': 1})\n",
        "        date_format = self.workbook.add_format({'align': 'center', 'valign': 'vcenter', 'border': 1, 'num_format': 'yyyy-mm-dd'})\n",
        "\n",
        "        sub_headers = ['開始予定日', '終了予定日', '残り日数', '予定頁数', '実績頁数']\n",
        "        cols_per_phase = len(sub_headers)\n",
        "\n",
        "        if data.empty or '区分' not in data.index.names:\n",
        "            worksheet.write(0, 0, \"処理対象の区分のデータが見つかりませんでした。\")\n",
        "            print(f\"「{sheet_name}」シートのデータが空のため、出力をスキップしました。\")\n",
        "            return\n",
        "\n",
        "        worksheet.set_column(0, 0, 35)\n",
        "\n",
        "        current_row = 0; today = datetime.now()\n",
        "        all_kukan = data.index.get_level_values('区分').unique()\n",
        "\n",
        "        for kukan in all_kukan:\n",
        "            kukan_phases = list(self.config.KUKAN_TO_PHASES_MAP.get(kukan, {}).keys())\n",
        "            if not kukan_phases: continue\n",
        "\n",
        "            total_cols = len(kukan_phases) * cols_per_phase\n",
        "            for i in range(total_cols): worksheet.set_column(i + 1, i + 1, 12)\n",
        "\n",
        "            worksheet.merge_range(current_row, 0, current_row, total_cols, kukan, title_format)\n",
        "            worksheet.set_row(current_row, 24); current_row += 2\n",
        "\n",
        "            header_row, sub_header_row, data_start_row = current_row, current_row + 1, current_row + 2\n",
        "\n",
        "            for i, phase in enumerate(kukan_phases):\n",
        "                start_col, end_col = 1 + i * cols_per_phase, 1 + (i + 1) * cols_per_phase - 1\n",
        "                if start_col <= end_col: worksheet.merge_range(header_row, start_col, header_row, end_col, phase, phase_header_format)\n",
        "                for j, sub_header in enumerate(sub_headers):\n",
        "                    worksheet.write(sub_header_row, start_col + j, sub_header, sub_header_format)\n",
        "\n",
        "            kukan_df = data[data.index.get_level_values('区分') == kukan]\n",
        "            all_targets = kukan_df.index.get_level_values('対象').unique()\n",
        "\n",
        "            for i, target in enumerate(all_targets):\n",
        "                row = data_start_row + i\n",
        "                worksheet.write(row, 0, target, target_format)\n",
        "                for j, phase in enumerate(kukan_phases):\n",
        "                    start_col = 1 + j * cols_per_phase\n",
        "                    try:\n",
        "                        record = kukan_df.loc[(kukan, target, phase)]\n",
        "                        start_date, end_date = record['開始予定日'], record['終了予定日']\n",
        "\n",
        "                        if pd.notna(start_date): worksheet.write(row, start_col, start_date, date_format)\n",
        "                        else: worksheet.write_blank(row, start_col, None, default_format)\n",
        "\n",
        "                        if pd.notna(end_date):\n",
        "                            worksheet.write(row, start_col + 1, end_date, date_format)\n",
        "                            days_left = (end_date - today).days\n",
        "                            worksheet.write(row, start_col + 2, days_left, default_format)\n",
        "                        else:\n",
        "                            worksheet.write_blank(row, start_col + 1, None, default_format)\n",
        "                            worksheet.write_blank(row, start_col + 2, None, default_format)\n",
        "\n",
        "                        worksheet.write(row, start_col + 3, record['予定頁数'], default_format)\n",
        "                        worksheet.write(row, start_col + 4, record['実績頁数'], default_format)\n",
        "                    except KeyError:\n",
        "                        for k in range(cols_per_phase): worksheet.write_blank(row, start_col + k, None, default_format)\n",
        "            current_row = data_start_row + len(all_targets) + 2\n",
        "        print(f\"「{sheet_name}」シートのカスタム出力が完了しました。\")\n",
        "\n",
        "def save_summaries_to_excel(summaries: Dict[str, pd.DataFrame], previous_totals_map: Dict[str, pd.DataFrame], execution_date: date, config: ReportConfig):\n",
        "    \"\"\"複数の集計結果DataFrameを1つのExcelファイルにシート分けして保存します。\"\"\"\n",
        "    output_filename = f\"{execution_date}-進捗課題状況.xlsx\"\n",
        "    print(f\"集計結果を'{output_filename}'に出力中...\")\n",
        "\n",
        "    with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:\n",
        "        workbook = writer.book\n",
        "\n",
        "        # シート名に応じて使用する書き込みクラスを定義\n",
        "        writer_map = {\n",
        "            config.SHEET_NAMES[\"progress\"]: StandardSheetWriter(workbook, config),\n",
        "            config.SHEET_NAMES[\"issue\"]: StandardSheetWriter(workbook, config),\n",
        "            config.SHEET_NAMES[\"new_transfer\"]: StandardSheetWriter(workbook, config),\n",
        "            config.SHEET_NAMES[\"missing_page\"]: StandardSheetWriter(workbook, config),\n",
        "            config.SHEET_NAMES[\"construction_prep\"]: ConstructionPrepSheetWriter(workbook, config)\n",
        "        }\n",
        "\n",
        "        for sheet_name, data in summaries.items():\n",
        "            if data is None or data.empty:\n",
        "                print(f\"INFO: シート '{sheet_name}' のデータが空のため、書き込みをスキップします。\")\n",
        "                continue\n",
        "\n",
        "            if sheet_name in writer_map:\n",
        "                writer_instance = writer_map[sheet_name]\n",
        "                previous_total = previous_totals_map.get(sheet_name)\n",
        "                writer_instance.write(sheet_name, data.copy(), previous_total)\n",
        "            else:\n",
        "                print(f\"WARNING: シート '{sheet_name}' に対応する書き込みクラスが見つかりません。\")\n",
        "\n",
        "    print(\"Excelファイルの出力が完了しました。\")\n",
        "\n",
        "# ==============================================================================\n",
        "# メイン処理\n",
        "# ==============================================================================\n",
        "def main():\n",
        "    \"\"\"スクリプトのエントリーポイント。\"\"\"\n",
        "    config = ReportConfig()\n",
        "    execution_date = datetime.now().date()\n",
        "\n",
        "    previous_totals = read_latest_past_totals(pattern='*-進捗課題状況.xlsx')\n",
        "    all_summaries = {}\n",
        "\n",
        "    try:\n",
        "        progress_df = load_and_prepare_progress_data(config.FILES['online_progress'], config.FILES['other_progress'], config.LOAD_CONFIG, config.LOAD_CONFIG['PROGRESS_SHEET_NAME'])\n",
        "        all_summaries[config.SHEET_NAMES[\"progress\"]] = summarize_document_progress(progress_df, config.PROCESS_DEFINITIONS, include_finalize=True)\n",
        "\n",
        "        new_transfer_df = load_and_prepare_new_file_transfer_data(config.FILES['other_progress'], config.LOAD_CONFIG, config.LOAD_CONFIG['NEW_FILE_TRANSFER_PROGRESS_SHEET_NAME'])\n",
        "        all_summaries[config.SHEET_NAMES[\"new_transfer\"]] = summarize_document_progress(new_transfer_df, config.PROCESS_DEFINITIONS, include_finalize=False)\n",
        "\n",
        "        issue_df = load_and_prepare_issue_data(config.FILES['issue_list'], config.LOAD_CONFIG)\n",
        "        all_summaries[config.SHEET_NAMES[\"issue\"]] = summarize_issues(issue_df, config.DOCUMENT_ORDER)\n",
        "\n",
        "        all_summaries[config.SHEET_NAMES[\"missing_page\"]] = extract_missing_page_tasks(config.FILES['online_progress'], config.FILES['other_progress'], config.LOAD_CONFIG, config.LOAD_CONFIG['PROGRESS_SHEET_NAME'])\n",
        "\n",
        "        raw_prep_df = load_and_prepare_construction_data(\n",
        "            config.FILES['construction_schedule'], config.LOAD_CONFIG, config.COL_NAMES_CONSTRUCTION_PREP\n",
        "        )\n",
        "        all_summaries[config.SHEET_NAMES[\"construction_prep\"]] = process_construction_prep_data(raw_prep_df, config.KUKAN_TO_PHASES_MAP)\n",
        "\n",
        "    except (FileNotFoundError, ValueError, IndexError) as e:\n",
        "        print(f\"\\nエラー: データ処理中に問題が発生しました。入力ファイルや設定を確認してください。\")\n",
        "        print(f\"詳細: {e}\")\n",
        "        return\n",
        "\n",
        "    save_summaries_to_excel(\n",
        "        summaries=all_summaries,\n",
        "        previous_totals_map=previous_totals,\n",
        "        execution_date=execution_date,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}